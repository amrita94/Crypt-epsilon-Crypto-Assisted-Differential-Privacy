\section{Optimizations}
In this section we propose two optimizations that leverages on the fact that the analyst is only interested in a  differentially private view of our private database. These DP based optimizations help in reducing the performance cost significantly which would have not been possible with just secure multi-party computation.
\\\textbf{1. Index} - Consider a conjunctive query predicate $A_1==v_1 \wedge A_2==v_2 \wedge A_3==v_3 $. If it so happens that the number of records satisfying $A_1==v_1$ is very low as compared to the total number of records, i.e., $ct_{A_1,v_1} << m$, then if a selection operation is performed alone on attribute $A_1$ then the size of the dataset to be considered for the subsequent clause $A_2==v_2 \wedge A_3==v_3$ reduces to only $ct_{A_1,v_1}$ as opposed to the whole dataset (size $m$). Our index optimization leverages on this idea - we create an index by sorting the database on an attribute of choice $A$. There are two heuristics that can be considered for selecting this indexing attribute $A$ - firstly $A$ should be a very frequently queried upon attribute. This is intuitive as this would mean a larger fraction of the queries will benefit from this optimization. Secondly if $\{v_1,...v_n\} \subset dom(A)$ is the set of most frequently queried values for attribute $A$, then $ct_{A,v_i}, i \in [n] << m$. This would ensure that the first selection operator performed alone on $A$ will filter out majority of the records and reduce the  dataset size to be considered for the subsequent predicate. 
The optimization can be implemented via a garbled circuit that \begin{enumerate}\item takes the entire database $\boldsymbol{\mathcal{\tilde{D}}}$ as an input and the attribute $A$ as an input from the \textsf{AS}.
\item takes the secret key $sk$ as an input from  the \textsf{CSP} \item Decrypts $\boldsymbol{\mathcal{\tilde{D}}}$ \item Sorts the decrypted database on $A$, i.e., the first $ct_{A,v_1}$ rows are the ones with value $v_1$ for attribute $A$, the next $ct_{A,v_2}$ are  the records with value $v_2$ for attribute $A$ and so on. \item  re-encrypts the sorted database \item Divide the domain of $A$ into $k$ bins such that each bin contains $s_A/k$ consecutive domain values. \item Construct a $k$ lengthed vector $\hat{V}$ such that $\hat{V}[i]=\sum_jct_{A,j}+\eta_i, i \in [k], j \in [\frac{s_A}{k}(i-1)+1,\frac{s_A}{k}i]$ where $\eta_i$ is a random laplace noise drawn from the distribution $Lap(\frac{k}{\epsilon})$ \item Return $\hat{V}$ and sorted $\boldsymbol{\mathcal{\tilde{D}}}_{sort}$\end{enumerate}
Next the \textsf{AS} computes a noisy CDF, $\hat{\mathcal{C}}$ over the $k$ bins using the noisy counts in $\hat{V}$ using inference based on isotonic regression \cite{cdf}. For executing a program conditioned as $\phi=A \in [v_s,v_e]$, we compute first compute $i_{start}=C[r_s-1], v_s \in [\frac{s_A}{k}\cdot(r_s-1)+1,\frac{s_A}{k}\cdot r_s]$, i.e., $v_s$ belongs to bin $r_s$   and  $i_{end}=C[r_e], v_e \in [\frac{s_A}{k}\cdot(r_e-1)+1,\frac{s_A}{k}\cdot r_e]$, i.e., $v_e$ belongs to bin $r_e$. We then run the program on this subset of records in $[]$. Note that for increased accuracy we can also consider preceding bins of $r_s-1$ for $i_{start}$ and succeeding bins of $r_e$ for $i_{end}$.
\begin{comment}
For answering queries of the form $\phi=A_1==v_1\wedge \ldots  \wedge A_n==v_n$, ideally we just need to compute for $A_2==v_2\wedge \ldots \wedge A_n==v_n$ on $ct_{A,v}$ number of records starting from position $\sum_{i=1}^{i=v-1}ct_{A,i}$ of $\boldsymbol{\mathcal{\tilde{D}}}_{sort}$. 

However the \textsf{AS} has access only to the noisy CDF over the $k$ bins $ct_{A,i}$. Note that when $\bar{i}_{start}=\bar{\hat{\mathcal{C}}}[v-1] < \sum_{i=1}^{i=v-1}ct_{A,i}$ and $\bar{i}_{end}= \bar{\hat{\mathcal{C}}}[v-1] > i_{start}+ct_{A,v}$, i.e., the indices computed from the noisy values  saddle over the true records satisfying $A==v$, then although we end up loosing in performance a bit, we are still guaranteed to compute the exact non-noisy count for records satisfying $\phi$. 

In all other cases, we end up disregarding some of the records that satisfy $A==v$, some of these rejected records in fact might additionally satisfy $A_1==v_1 \wedge \ldots \wedge A_n==v_n$. Thus we might get inaccurate answer for query predicate $\phi$ (note that here we are talking about the encrypted true count of the given query predicate that is computed by the AS via a series of transformations before applying the LaplaceMechanism primitive).  An effective heuristic to tackle this can be to compensate for the expected laplacian error as follows  $\bar{i}_{start}= \bar{\hat{\mathcal{C}}}[v-1]-\frac{2}{\epsilon}$ and $\bar{i}_{end}=\bar{\hat{\mathcal{C}}}[v]+\frac{2}{\epsilon}$. Also note that answering differentially private  range queries   on attribute $A$ can also be directly done from the noisy CDF $\bar{\hat{\mathcal{C}}}$ 
\end{comment}
 %\item GroupBy*($\mathbf{V},sk$)- This primitive is an extension of the previous GroupBy transformation. 
 \\
\textbf{2. } \textbf{Range Tree}- Range queries constitute a very popular category of queries for typical databases and range trees are a popular data structure constructed to speed up range query answering. A 1-dimensional range tree for an attribute $A$ is an ordered data structure such that the leaf nodes correspond to the individual counts $ct_{A,i}$, $i$ increasing from left to right while the parent node stores the sum of the counts of its children. Hence an useful optimization for our setting can be pre-computing the range tree for some attributes. In Crypt$\epsilon$ we construct a noisy range tree for some of the attribute. The sensitivity for each such noisy count is $\log k$ where $k$ is the domain size of the attribute. For answering any arbitrary range query, we need to access at most $2\log k$ nodes of the range tree. Thus to answer all possible range queries for the given attribute, the total squared error accumulated is $O(\frac{k^2(\log k)^3 }{\epsilon^2})$. In contrast for the naive case, we would have incurred error $O(\frac{k^4}{\epsilon^2})$. Hence this range tree optimization not only gives us a huge performance boost but also results in better answer accuracy. 
\paragraph*{\textbf{Optimized Crypt$\epsilon$ programs}}
Let us reconsider the example programs covered in section 5. Both Program 1 and Program 2 can be optimized by constructing a range tree over attribute $Age$. Program  4 and Program 5  on the other hand can be improved by the differentially private index over attribute $NativeCountry$ while for Program 6 we can create the index over attribute $Gender$.