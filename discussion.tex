\section{Discussion}
\subsection{Joint Laplace Noise Generation}\label{jointLap}
Recall that in Crypt$\epsilon$ both the servers, \textsf{AS} and \textsf{CSP} has to add two separate instances of laplace noise before releasing the output. Thus the error incurred in Crypt$\epsilon$ is quantitatively twice that of the traditional \textsf{CDP} model. However there is an alternative way of jointly computing a single instance of the laplace noise via a secure multi party computation protocol \cite{Djoin}. For this, the CSP generates a garbled circuit that \begin{enumerate}\item takes a $l$-bit random string, $S_1$ as an input from the \textsf{CSP}
    \item takes another $l$-bit random string $S_2$ as an input from the \textsf{AS} \item performs $S=S_1 xor S_2$  and uses it to generate an instance of random noise, $\eta$ drawn from the distribution $Lap(\frac{1}{\epsilon})$ following the fundamental law of transformation of probabilities \item encrypts $\eta$ and returns $\boldsymbol{\eta}=labEnc_{pk}(\eta)$\end{enumerate}
Hence using this approach, we need to add just one instance of the Laplace noise and thus get back the exact same accuracy guarantees of the \textsf{CDP} model. However owing to the garbled circuit, this implementation is computationally heavier and hence we go for the two phase noise addition implementation for Crypt $\epsilon$ in this paper.
\subsection{Separation from LDP model}
As mentioned in section 1, the power of the \textsf{LDP} model is strictly lesser than that of the \textsf{CDP} model \cite{Kasivi,mixnets}. However, by virtue of secure computation, we can potentially implement all the functionalities of the \textsf{CDP} model in our two-server model. Functional efficiency might be a point of contention in certain cases but nothing in Crypt$\epsilon$'s architecture pose any  restriction on its algorithmic expressibility. Recall that the power of the \textsf{LDP} model is equivalent to that of the "Statistical Query Model". In this section we showcase three different queries cases that are computable efficiently in Crypt$\epsilon$ but infeasible in the standard \textsf{LDP} model. 
An important point to be noted here is that the power of the shuffler or mixnet model  (which is obtained by augmenting \textsf{LDP} with anonymization via shuffling), as proposed in \cite{Prochlo, mixnets,amplification},  lies strictly between that of traditional \textsf{LDP} and \textsf{CDP}. Thus the two-server model of Crypt$\epsilon$ differs from this line of work in three major ways. Firstly, as discussed above, Crypt$\epsilon$ results in no reduction in expressibility as compared to that of the \textsf{CDP} model. Secondly, the mixnet/shuffler model results in an approximate DP guarantee $(\epsilon\sqrt{\frac{\log\frac{1}{\delta}}{n}},\delta)$ which incurs an expected error of $O(\epsilon\sqrt{\log\frac{1}{\delta}})$.  In practice, $\delta$ has to be at least $\frac{1}{n}$ in order to get some meaningful privacy. In contrast Crypt$\epsilon$ achieves the the same order of accuracy guarantees as that of the \textsf{CDP} model. Finally, the trust assumptions of the shuffler/mixnet model differ from that of \system. Google's implementation relies on a trusted intermediary shuffler which they implement via trusted hardware enclaves. However truly secure hardware enclaves are notoriously difficult to achieve in practice \cite{Foreshadow}. The mixnet model on the other hand requires a  mix network or mixnet which is a protocol involving several computers that inputs a sequence
of encrypted messages, and outputs a uniformly random permutation of those messages' plaintexts.  Their trust assumption is that at least one of the servers needs to behave honestly. For Crypt$\epsilon$ both the servers are completely untrusted under the constraint that they are non-colluding and follow the protocols semi-honestly. \subsection*{DNF Queries}
The class of DNF queries fall outside the scope of statistical query models \cite{DNF}. Hence it is infeasible to answer counting queries based on a predicate with a disjunction in the \textsf{LDP} model. However, we can answer them in Crypt$\epsilon$ as follows.
Consider a DNF query 
\begin{gather}\phi = (A_{11}\land ...\land A_{1k}) \vee ... \vee (A_{t1}\land ... A_{tl}), t, k,l \in \mathcal{Z}_{\geq 0} \end{gather}
Let $Attribute(\phi)$ denote the set of all attributes in $\mathcal{A}$ that appear in the boolean condition $\phi$. For e.g., if $\phi = \big((\mathcal{A}_1==v_1) \land \mathcal{A}_2==v_2) \vee \mathcal{A}_3==v_3 \big)$, then  we have $Attribute(\phi)=\{\mathcal{A}_1, \mathcal{A}_2,\mathcal{A}_3\}$. \begin{enumerate}\item Firstly, the \textsf{AS} computes the attribute set $A^*=Attribute(\phi)$.
\item Next the \textsf{AS} performs a \textsf{Project} transformation on inputs attribute set $A^*$ and the entire encrypted database $\boldsymbol{\tilde{\mathcal{D}}}$. 
\item Let $A^*= \{A^*_1,A^*_2,\ldots,A^*_t\}, t \leq k$. The \textsf{AS} constructs the encrypted one-hot-coding over the entire $t$-dimension $\lq$attribute' $\mathcal{A}^*=\times_{i=1}^t A^*_i$ by $(t-1)$ iterative application of the cross product transformation. 
\item Note that the result of the preceding step is a $m\times 1$ table where the $i^{th} , i \in [m]$ record corresponds to the encrypted one-hot-coding over the entire $t$-dimension domain space of $\mathcal{A}^*$ of data owner $\textsf{DO}_i$. Now the \textsf{AS} simply applies the \textsf{Filter} transformation on this table with predicate $\phi'$  such that $\phi'$ is the equivalent of $\phi$ when expressed in terms of the new  attribute $\mathcal{A}^*$.
\item This is followed by performing the \textsf{Count} transformation and the \textsf{Laplace} transformation to obtain the final result. 
\end{enumerate}
\subsection*{Variable Selection Problem} The variable selection problem is an optimization problem described as follows. Given a set of counting queries, the problem finds the query with nearly largest value, i.e., computes an approximate argmax. In \cite{mixnets} Cheu et al. prove that the sample complexity of this problem in the "one-message" mixnet model (i.e., each user send only a single message into the shuffle) is exponentially larger than that of the \textsf{CDP} model. The variable-selection problem is actually equivalent to the exponential mechanism\cite{Dork} in the \textsf{CDP} model. Moreover the exponential mechanism is simply a variant of the "Report Noisy-Max" algorithm with a different noise distribution \cite{Nm}. Thus essentially, the \textsf{NoisyMax} primitive in Crypt$\epsilon$ is capable of solving the variable-selection problem efficiently. 
\subsection*{Number of distinct values}
Consider the problem of computing the number of distinct values out of a set of $m$ user data where the domain of the values is $S$ and $m<<|S|$. In the \textsf{LDP} model, for small sizes of $S$, one can construct a frequency oracle and compute the number of values with non-zero count with some careful thresholding \cite{LDP1}. However, if the size of $S$ is huge then it becomes computationally infeasible to deploy the aforementioned mechanism. For example, if the values correspond to different URLs, since the total domain size is $2^{64}$, computability limitations make this problem infeasible to be solved in the \textsf{LDP} setting. Although for our discussion in the paper we have considered the one-hot-coding as our preferred data encoding scheme, Crypt$\epsilon$ architecturally can support any arbitrary encoding scheme.  For instance, for URLs the data owners can instead use the domain name based encoding (i.e., subdomain.secondleveldomain.topleveldomain) for encrypting their data. Following this, an appropriate garbled circuit to count the number of distinct values from this encrypted dataset (which can be defined as a new Crypt$\epsilon$ primitive) can answer the above query in the Crypt$\epsilon$ setting.

\begin{comment}\subsection{Answering queries with disjunctions in predicate} Now let us consider a DNF query predicate $\phi=\phi_1 \vee \phi_2$ where $\phi_1=(A_1==v_1 \wedge \ldots \wedge A_n==v_n)$ and $\phi_2=(A'_1==v'_1 \wedge \ldots \wedge A'_n==v'_n)$ are two conjunctive clauses. For a given record assume, \begin{gather*}\mathbf{d}=\mathbf{c_1}\oplus \mathbf{c_2}-labMult(\mathbf{c_1,c_2}) \\
\mathbf{c_1}=genLabMult(\mathbf{\tilde{R}}_{A1}[v_1], \ldots ,\mathbf{\tilde{R}}_{An}[v_n] ) \\ \mathbf{c_1}=genLabMult(\mathbf{\tilde{R}}_{A1}[v_1], \ldots ,\mathbf{\tilde{R}}_{An}[v_n] )\end{gather*} Note that $d=1$  only iff  the record satisfies $\phi$. Thus for a two clause  DNF predicate as above, the optimized Filter transformation takes as input $x \times y$ encrypted table $\tilde{\mathbf{T}}$ with attribute set $\bigcup_{i=1}^n Attribute(\phi_i)$ and outputs a $x \times 1$ encrypted table $\mathbf{\tilde{T}}'$ such that \begin{gather} \mathbf{\tilde{T}}'[i]= \mathbf{c_1}\oplus \mathbf{c_2}-labMult(\mathbf{c_1,c_2}) \\
\mathbf{c_1}=genLabMult(\mathbf{\tilde{R}}_{A1}[v_1], \ldots ,\mathbf{\tilde{R}}_{An}[v_n] ) \\ \mathbf{c_1}=genLabMult(\mathbf{\tilde{R}}_{A1}[v_1], \ldots ,\mathbf{\tilde{R}}_{An}[v_n] )\end{gather} For $t>2$ clauses in a DNF, apply the Filter transformation pairwise for $\lceil \log t \rceil$ iterations. 
\end{comment}
