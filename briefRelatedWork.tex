\section{Related Work}\label{sec:related-short}
\textit{Differential Privacy }- Introduced by Dwork et al. in \cite{Dork}, differential privacy has enjoyed immense attention from both academia and industry in the last decade. Some of the most recent directions in the \textsf{CDP} model include \cite{MVG,Blocki,AHP,DAWA,hist1,hist2,hist3,hist4,hist6,hist7,hist8,A1,A2,A3,A4,A5,A6,A7,A8,u1,u2,MWEM}. The most prominent work in \textsf{LDP} include \cite{LDP1, LDP2, Rappor1,HH,Rappor2,HH2,Cormode, CALM,15,itemset}.
Recently, it has been showed that augmenting the local differential privacy setting by an additional layer of anonymity can improve the privacy
guarantees (or equivalently decrease error bound) \cite{mixnets,Prochlo,amplification}.  An important point to be noted here is that the power of this new model (known as shuffler/mixnet model) lies strictly between that of traditional \textsf{LDP} and \textsf{CDP}. The two-server model of Crypt$\epsilon$ differs from this line of work in three ways. Firstly, Crypt$\epsilon$ results in no reduction in expressibility as compared to that of the \textsf{CDP} model (see Appendix \ref{app:sepldp}). Secondly, the shuffler/mixnet model results in an approximate DP guarantee $(\epsilon\sqrt{\frac{\log\frac{1}{\delta}}{n}},\delta)$ which incurs an expected error of $O(\epsilon\sqrt{\log\frac{1}{\delta}})$.  In practice, $\delta$ has to be at least $\frac{1}{n}$ in order to get meaningful privacy. In contrast Crypt$\epsilon$ achieves the the same order of accuracy guarantees as that of \textsf{CDP}. Finally, the shuffler/mixnet model and \system have certain differences in their respective trust assumptions. For more details see Appendix D.2. %Google's implementation relies on a trusted intermediary shuffler which they implement via trusted hardware enclaves. However truly secure hardware enclaves are notoriously difficult to achieve in practice \cite{Foreshadow}. The mixnet model on the other hand requires a  mix network or mixnet which is a protocol involving several computers that inputs a sequenceof encrypted messages, and outputs a uniformly random permutation of those messages' plaintexts.  Their trust assumption is that at least one of the servers needs to behave honestly. For Crypt$\epsilon$ both the servers are completely untrusted under the constraint that they are non-colluding and follow the protocols semi-honestly.
\\\textit{Two-Server Model} - The two-server model is a popular choice especially for privacy preserving machine learning approaches where typically one of the servers manages the cryptographic primitives while the other handles computation. Examples of this include \cite{Boneh1,Boneh2,Ridge2,Matrix2,secureML,LReg,Ver}. \\\textit{Homomorphic Encryption } - Recently, there has been a surge in  privacy preserving solutions using homomorphic encryptions due to improved primitives. A lot of the aforementioned two-server models employ homomorphic encryption \cite{Boneh1,Boneh2,LReg,Matrix2}.  Additionally it is used in \cite{CryptoDL,CryptoNet,NN, Irene2, grid}.
%A detailed discussion on related work is presented in  Appendix \ref{app:related}.

